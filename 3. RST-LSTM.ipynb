{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the RST-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing train/test files for mask-related classification: 100%|██████████| 5/5 [00:04<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for fold in tqdm(range(5), desc=\"Writing train/test files for mask-related classification\"):\n",
    "    pathname = f'data/fold_{fold}'\n",
    "    \n",
    "    train = pickle.load(open(f'data/fold_{fold}/train.pkl', 'rb'))\n",
    "    train['tree'] = train['annot'].map(lambda row: row['rst'][0])\n",
    "    train['label1'] = train.masks_stance.map(str)\n",
    "    train['label2'] = train.masks_argument.map(str)\n",
    "    train[['text_id', 'tree', 'label1', 'label2']].to_pickle(f'data/fold_{fold}/train_mask_rst.pkl')\n",
    "\n",
    "    test = pickle.load(open(f'data/fold_{fold}/test.pkl', 'rb'))\n",
    "    test['tree'] = test['annot'].map(lambda row: row['rst'][0])\n",
    "    test['label1'] = test.masks_stance.map(str)\n",
    "    test['label2'] = test.masks_argument.map(str)\n",
    "    test[['text_id', 'tree', 'label1', 'label2']].to_pickle(f'data/fold_{fold}/test_mask_rst.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 13\n",
      "text: Иди почитай инсту наших городских пабликов где каждый 10 ый пишет что у них знакомый откуда то вернулся и плевал на карантин , у нас никто ниче не раздает , раздавать нечего в аптеках нет ничего )\n",
      "proba: 1.0\n",
      "relation: contrast\n",
      "nuclearity: NN\n",
      "left: Иди почитай инсту наших городских пабликов где каждый 10 ый пишет что у них знакомый откуда то вернулся и плевал на карантин ,\n",
      "right: у нас никто ниче не раздает , раздавать нечего в аптеках нет ничего )\n",
      "start: 0\n",
      "end: 196\n"
     ]
    }
   ],
   "source": [
    "print(test.iloc[0].tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config for masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting configs/rstbert_masks_0.jsonnet\n"
     ]
    }
   ],
   "source": [
    "%%writefile configs/rstbert_masks_0.jsonnet\n",
    "\n",
    "local embedding_dim = 768;\n",
    "local foldnum = 0;\n",
    "local max_length = 512;\n",
    "local lr = std.parseJson(std.extVar('lr'));\n",
    "local dropout = std.parseJson(std.extVar('dropout'));\n",
    "local batch_size = std.parseJson(std.extVar('batch_size'));\n",
    "local treelstm_hidden_size = std.parseJson(std.extVar('treelstm_hidden_size'));\n",
    "local dataset_reader_type = \"models_scripts.dataset_readers.rst_tree_reader.IsaNLPRSTDatasetReader\";\n",
    "local model_type = \"models_scripts.models.two_outputs_tree_lstm_clf.TwoOutputsTreeLSTM\";\n",
    "local model_name = \"DeepPavlov/rubert-base-cased-conversational\";\n",
    "\n",
    "{\n",
    "  vocabulary: {\n",
    "    non_padded_namespaces: [\"tokens\", \"labels1\", \"labels2\"]\n",
    "  },\n",
    "  dataset_reader: {\n",
    "      type: dataset_reader_type,\n",
    "      num_labels1: 4,\n",
    "      num_labels2: 4,\n",
    "      tokenizer: {\n",
    "        type: \"pretrained_transformer\",\n",
    "        model_name: model_name,\n",
    "        max_length: max_length,\n",
    "      },\n",
    "      token_indexers: {\n",
    "          tokens: {\n",
    "            type: \"pretrained_transformer\",\n",
    "            model_name: model_name,\n",
    "            max_length: max_length,\n",
    "            namespace: 'tokens',\n",
    "      },\n",
    "    },\n",
    "  },\n",
    "  train_data_path: 'data/fold_' + foldnum + '/train_mask_rst.pkl',\n",
    "  validation_data_path: 'data/fold_' + foldnum + '/test_mask_rst.pkl',\n",
    "  model: {\n",
    "    type: model_type,\n",
    "    dropout: dropout,\n",
    "    num_labels1: 4,\n",
    "    num_labels2: 4,\n",
    "    label1_weights: [0.2, 0.3, 1.0, 1.0],\n",
    "    label2_weights: [0.1, 0.1, 1.0, 1.0],\n",
    "    treelstm_hidden_size: treelstm_hidden_size,\n",
    "    text_field_embedder: {\n",
    "        token_embedders: {\n",
    "            tokens: {\n",
    "              type: \"pretrained_transformer\",\n",
    "              model_name: model_name,\n",
    "              max_length: max_length,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    seq2vec_encoder: {\n",
    "        type: \"bert_pooler\",\n",
    "           pretrained_model: model_name,\n",
    "           requires_grad: false,\n",
    "           dropout: 0.2,\n",
    "    },\n",
    "    initializer: {\n",
    "        regexes: [\n",
    "        [\"_text_field_embedder.*|_seq2vec_encoder.*|_classification_layer1.*|_classification_layer2.*\",\n",
    "            {\n",
    "                \"type\": \"pretrained\",\n",
    "                \"weights_file_path\": \"convbert_masks/fold_\" + foldnum + \"/weights.th\",\n",
    "            }\n",
    "        ],\n",
    "        ],\n",
    "    },\n",
    "  },\n",
    "  data_loader: {\n",
    "    batch_sampler: {\n",
    "      type: 'bucket',\n",
    "      batch_size: batch_size,\n",
    "    },\n",
    "  },\n",
    "  trainer: {\n",
    "    optimizer: {\n",
    "      type: \"adam\",\n",
    "      lr: lr,\n",
    "    },\n",
    "    learning_rate_scheduler: {\n",
    "      type: \"slanted_triangular\",\n",
    "      cut_frac: 0.06\n",
    "    },\n",
    "    grad_norm: 5.0,\n",
    "    grad_clipping: 5.0,\n",
    "    validation_metric: '+all_mean',\n",
    "    num_serialized_models_to_keep: 1,\n",
    "    num_epochs: 20,\n",
    "    patience: 3,\n",
    "    cuda_device: 0,\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting configs/hparams.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile configs/hparams.json\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"type\": \"int\",\n",
    "    \"attributes\": {\n",
    "      \"name\": \"treelstm_hidden_size\",\n",
    "      \"low\": 50,\n",
    "      \"high\": 100\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"int\",\n",
    "    \"attributes\": {\n",
    "      \"name\": \"batch_size\",\n",
    "      \"low\": 1,\n",
    "      \"high\": 12\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"float\",\n",
    "    \"attributes\": {\n",
    "      \"name\": \"dropout\",\n",
    "      \"low\": 0.3,\n",
    "      \"high\": 0.5\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"float\",\n",
    "    \"attributes\": {\n",
    "      \"name\": \"lr\",\n",
    "      \"low\": 2e-5,\n",
    "      \"high\": 2e-3,\n",
    "      \"log\": true\n",
    "    }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tune_rstbert_masks.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile tune_rstbert_masks.sh\n",
    "\n",
    "export METHOD=rstbert_masks\n",
    "rm -r $METHOD\n",
    "mkdir $METHOD\n",
    "export FOLD=0\n",
    "export STUDY_NAME=rstbert_test1\n",
    "allennlp tune configs/${METHOD}_${FOLD}.jsonnet configs/hparams.json --serialization-dir $METHOD/fold_${FOLD} \\\n",
    "    --study-name $STUDY_NAME \\\n",
    "    --skip-if-exists \\\n",
    "    --metrics best_validation_all_mean \\\n",
    "    --direction maximize\n",
    "rm rstbert_masks/fold_0/trial_*/*.th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def find_top_trials(path):\n",
    "    mean_all = dict()\n",
    "    for directory in glob.glob(path):\n",
    "        try:\n",
    "            metrics = json.load(open(os.path.join(directory, 'metrics.json'), 'r'))\n",
    "            mean_all[directory] = (metrics.get('best_validation_all_mean'), \n",
    "                                   metrics.get('best_validation_f1_1_mean'),\n",
    "                                   metrics.get('best_validation_f1_2_mean'))\n",
    "        except:\n",
    "            pass\n",
    "    return {key: value for key, value in sorted(mean_all.items(), key=lambda x: x[1][0], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = find_top_trials('rstbert_masks/fold_0/trial_*')\n",
    "ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-08 16:17:11,510 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-02-08 16:17:11,941 - INFO - allennlp.common.plugins - Plugin allennlp_optuna available\n",
      "batch_size=9 dropout=0.36010392436488825 lr=0.000507610262905939 treelstm_hidden_size=76\n"
     ]
    }
   ],
   "source": [
    "! allennlp best-params --study-name rstbert_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rstbert_masks.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile rstbert_masks.sh\n",
    "\n",
    "export METHOD=rstbert_masks\n",
    "rm -r $METHOD\n",
    "mkdir $METHOD\n",
    "export batch_size=4\n",
    "export dropout=0.4\n",
    "export lr=3e-05\n",
    "export treelstm_hidden_size=94\n",
    "\n",
    "python utils/make_k_copies.py --filename configs/${METHOD}_0.jsonnet --k 5\n",
    "\n",
    "export FOLD=0\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_mask_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_mask_rst.pkl \\\n",
    "#                  --include-package models_scripts\n",
    "\n",
    "export FOLD=1\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_mask_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_mask_rst.pkl \\\n",
    "#                  --include-package models_scripts\n",
    "\n",
    "export FOLD=2\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_mask_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_mask_rst.pkl \\\n",
    "#                  --include-package models_scripts\n",
    "\n",
    "export FOLD=3\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_mask_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_mask_rst.pkl \\\n",
    "#                  --include-package models_scripts\n",
    "\n",
    "export FOLD=4\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_mask_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_mask_rst.pkl \\\n",
    "#                  --include-package models_scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config for vaccines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing train/test files for vaccines-related classification: 100%|██████████| 5/5 [00:06<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "for fold in tqdm(range(5), desc=\"Writing train/test files for vaccines-related classification\"):\n",
    "    pathname = f'data/fold_{fold}'\n",
    "    \n",
    "    train = pickle.load(open(f'data/fold_{fold}/train.pkl', 'rb'))\n",
    "    train['tree'] = train['annot'].map(lambda row: row['rst'][0])\n",
    "    train['label1'] = train.vaccines_stance.map(str)\n",
    "    train['label2'] = train.vaccines_argument.map(str)\n",
    "    train[['text_id', 'tree', 'label1', 'label2']].to_pickle(f'data/fold_{fold}/train_vaccines_rst.pkl')\n",
    "\n",
    "    test = pickle.load(open(f'data/fold_{fold}/test.pkl', 'rb'))\n",
    "    test['tree'] = test['annot'].map(lambda row: row['rst'][0])\n",
    "    test['label1'] = test.vaccines_stance.map(str)\n",
    "    test['label2'] = test.vaccines_argument.map(str)\n",
    "    test[['text_id', 'tree', 'label1', 'label2']].to_pickle(f'data/fold_{fold}/test_vaccines_rst.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting configs/rstbert_vaccines_0.jsonnet\n"
     ]
    }
   ],
   "source": [
    "%%writefile configs/rstbert_vaccines_0.jsonnet\n",
    "\n",
    "local embedding_dim = 768;\n",
    "local foldnum = 0;\n",
    "local max_length = 512;\n",
    "local lr = std.parseJson(std.extVar('lr'));\n",
    "local dropout = std.parseJson(std.extVar('dropout'));\n",
    "local batch_size = std.parseJson(std.extVar('batch_size'));\n",
    "local treelstm_hidden_size = std.parseJson(std.extVar('treelstm_hidden_size'));\n",
    "local dataset_reader_type = \"models_scripts.dataset_readers.rst_tree_reader.IsaNLPRSTDatasetReader\";\n",
    "local model_type = \"models_scripts.models.two_outputs_tree_lstm_clf.TwoOutputsTreeLSTM\";\n",
    "local model_name = \"DeepPavlov/rubert-base-cased-conversational\";\n",
    "\n",
    "{\n",
    "  vocabulary: {\n",
    "    non_padded_namespaces: [\"tokens\", \"labels1\", \"labels2\"]\n",
    "  },\n",
    "  dataset_reader: {\n",
    "      type: dataset_reader_type,\n",
    "      num_labels1: 4,\n",
    "      num_labels2: 4,\n",
    "      tokenizer: {\n",
    "        type: \"pretrained_transformer\",\n",
    "        model_name: model_name,\n",
    "        max_length: max_length,\n",
    "      },\n",
    "      token_indexers: {\n",
    "          tokens: {\n",
    "            type: \"pretrained_transformer\",\n",
    "            model_name: model_name,\n",
    "            max_length: max_length,\n",
    "            namespace: 'tokens',\n",
    "      },\n",
    "    },\n",
    "  },\n",
    "  train_data_path: 'data/fold_' + foldnum + '/train_vaccines_rst.pkl',\n",
    "  validation_data_path: 'data/fold_' + foldnum + '/test_vaccines_rst.pkl',\n",
    "  model: {\n",
    "    type: model_type,\n",
    "    dropout: dropout,\n",
    "    num_labels1: 4,\n",
    "    num_labels2: 4,\n",
    "    label1_weights: [0.1, 0.4, 1.0, 1.0],\n",
    "    label2_weights: [0.1, 0.1, 0.6, 1.0],\n",
    "    treelstm_hidden_size: treelstm_hidden_size,\n",
    "    text_field_embedder: {\n",
    "        token_embedders: {\n",
    "            tokens: {\n",
    "              type: \"pretrained_transformer\",\n",
    "              model_name: model_name,\n",
    "              max_length: max_length,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    seq2vec_encoder: {\n",
    "        type: \"bert_pooler\",\n",
    "           pretrained_model: model_name,\n",
    "           requires_grad: false,\n",
    "           dropout: 0.2,\n",
    "    },\n",
    "    initializer: {\n",
    "        regexes: [\n",
    "        [\"_text_field_embedder.*|_seq2vec_encoder.*|_classification_layer1.*|_classification_layer2.*\",\n",
    "            {\n",
    "                \"type\": \"pretrained\",\n",
    "                \"weights_file_path\": \"convbert_vaccines/fold_\" + foldnum + \"/weights.th\",\n",
    "            }\n",
    "        ],\n",
    "        ],\n",
    "    },\n",
    "  },\n",
    "  data_loader: {\n",
    "    batch_sampler: {\n",
    "      type: 'bucket',\n",
    "      batch_size: batch_size,\n",
    "    },\n",
    "  },\n",
    "  trainer: {\n",
    "    optimizer: {\n",
    "      type: \"adam\",\n",
    "      lr: lr,\n",
    "#       weight_decay: 0.1,\n",
    "    },\n",
    "    learning_rate_scheduler: {\n",
    "      type: \"slanted_triangular\",\n",
    "      cut_frac: 0.06\n",
    "    },\n",
    "    grad_norm: 5.0,\n",
    "    grad_clipping: 5.0,\n",
    "    validation_metric: '+all_mean',\n",
    "    num_serialized_models_to_keep: 1,\n",
    "    num_epochs: 20,\n",
    "    patience: 3,\n",
    "    cuda_device: 1,\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tune_rstbert_vaccines.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile tune_rstbert_vaccines.sh\n",
    "\n",
    "export METHOD=rstbert_vaccines\n",
    "rm -r $METHOD\n",
    "mkdir $METHOD\n",
    "export FOLD=0\n",
    "export STUDY_NAME=rstbert_test2\n",
    "# optuna delete-study $STUDY_NAME\n",
    "allennlp tune configs/${METHOD}_${FOLD}.jsonnet configs/hparams.json --serialization-dir $METHOD/fold_${FOLD} \\\n",
    "    --study-name $STUDY_NAME \\\n",
    "    --skip-if-exists \\\n",
    "    --metrics best_validation_all_mean \\\n",
    "    --direction maximize\n",
    "rm rstbert_vaccines/fold_0/trial_*/*.th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-05 20:31:26,545 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-02-05 20:31:26,965 - INFO - allennlp.common.plugins - Plugin allennlp_optuna available\n",
      "batch_size=3 dropout=0.2 lr=2.506909891571783e-05 treelstm_hidden_size=53\n"
     ]
    }
   ],
   "source": [
    "! allennlp best-params --study-name rstbert_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_top_trials('rstbert_vaccines/fold_0/trial_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rstbert_vaccines.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile rstbert_vaccines.sh\n",
    "\n",
    "export METHOD=rstbert_vaccines\n",
    "rm -r $METHOD\n",
    "mkdir $METHOD\n",
    "export batch_size=3\n",
    "export dropout=0.2\n",
    "export lr=2.5e-05\n",
    "export treelstm_hidden_size=53\n",
    "\n",
    "python utils/make_k_copies.py --filename configs/${METHOD}_0.jsonnet --k 5\n",
    "\n",
    "export FOLD=0\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_vaccines_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_vaccines_rst.pkl \\\n",
    "#                  --include-package models_scripts\n",
    "\n",
    "export FOLD=1\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_vaccines_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_vaccines_rst.pkl \\\n",
    "#                  --include-package models_scripts\n",
    "\n",
    "export FOLD=2\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_vaccines_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_vaccines_rst.pkl \\\n",
    "#                  --include-package models_scripts\n",
    "\n",
    "export FOLD=3\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_vaccines_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_vaccines_rst.pkl \\\n",
    "#                  --include-package models_scripts\n",
    "\n",
    "export FOLD=4\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_vaccines_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_vaccines_rst.pkl \\\n",
    "#                  --include-package models_scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config for quarantine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing train/test files for quarantine-related classification: 100%|██████████| 5/5 [00:05<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "for fold in tqdm(range(5), desc=\"Writing train/test files for quarantine-related classification\"):\n",
    "    pathname = f'data/fold_{fold}'\n",
    "    \n",
    "    train = pickle.load(open(f'data/fold_{fold}/train.pkl', 'rb'))\n",
    "    train['tree'] = train['annot'].map(lambda row: row['rst'][0])\n",
    "    train['label1'] = train.quarantine_stance.map(str)\n",
    "    train['label2'] = train.quarantine_argument.map(str)\n",
    "    train[['text_id', 'tree', 'label1', 'label2']].to_pickle(f'data/fold_{fold}/train_quarantine_rst.pkl')\n",
    "\n",
    "    test = pickle.load(open(f'data/fold_{fold}/test.pkl', 'rb'))\n",
    "    test['tree'] = test['annot'].map(lambda row: row['rst'][0])\n",
    "    test['label1'] = test.quarantine_stance.map(str)\n",
    "    test['label2'] = test.quarantine_argument.map(str)\n",
    "    test[['text_id', 'tree', 'label1', 'label2']].to_pickle(f'data/fold_{fold}/test_quarantine_rst.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    3667\n",
       "1     1092\n",
       "2      476\n",
       "0      139\n",
       "Name: quarantine_stance, dtype: int64"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.quarantine_stance.map(str).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    3667\n",
       "1     1425\n",
       "2      175\n",
       "0      107\n",
       "Name: quarantine_argument, dtype: int64"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.quarantine_argument.map(str).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting configs/rstbert_quarantine_0.jsonnet\n"
     ]
    }
   ],
   "source": [
    "%%writefile configs/rstbert_quarantine_0.jsonnet\n",
    "\n",
    "local embedding_dim = 768;\n",
    "local foldnum = 0;\n",
    "local max_length = 512;\n",
    "local lr = std.parseJson(std.extVar('lr'));\n",
    "local dropout = std.parseJson(std.extVar('dropout'));\n",
    "local batch_size = std.parseJson(std.extVar('batch_size'));\n",
    "local treelstm_hidden_size = std.parseJson(std.extVar('treelstm_hidden_size'));\n",
    "local dataset_reader_type = \"models_scripts.dataset_readers.rst_tree_reader.IsaNLPRSTDatasetReader\";\n",
    "local model_type = \"models_scripts.models.two_outputs_tree_lstm_clf.TwoOutputsTreeLSTM\";\n",
    "local model_name = \"DeepPavlov/rubert-base-cased-conversational\";\n",
    "\n",
    "{\n",
    "  vocabulary: {\n",
    "    non_padded_namespaces: [\"tokens\", \"labels1\", \"labels2\"]\n",
    "  },\n",
    "  dataset_reader: {\n",
    "      type: dataset_reader_type,\n",
    "      num_labels1: 4,\n",
    "      num_labels2: 4,\n",
    "      tokenizer: {\n",
    "        type: \"pretrained_transformer\",\n",
    "        model_name: model_name,\n",
    "        max_length: max_length,\n",
    "      },\n",
    "      token_indexers: {\n",
    "          tokens: {\n",
    "            type: \"pretrained_transformer\",\n",
    "            model_name: model_name,\n",
    "            max_length: max_length,\n",
    "            namespace: 'tokens',\n",
    "      },\n",
    "    },\n",
    "  },\n",
    "  train_data_path: 'data/fold_' + foldnum + '/train_quarantine_rst.pkl',\n",
    "  validation_data_path: 'data/fold_' + foldnum + '/test_quarantine_rst.pkl',\n",
    "  model: {\n",
    "    type: model_type,\n",
    "    dropout: dropout,\n",
    "    num_labels1: 4,\n",
    "    num_labels2: 4,\n",
    "    label1_weights: [0.1, 0.1, 0.3, 1.0],\n",
    "    label2_weights: [0.1, 0.1, 0.6, 1.0],\n",
    "    treelstm_hidden_size: treelstm_hidden_size,\n",
    "    text_field_embedder: {\n",
    "        token_embedders: {\n",
    "            tokens: {\n",
    "              type: \"pretrained_transformer\",\n",
    "              model_name: model_name,\n",
    "              max_length: max_length,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    seq2vec_encoder: {\n",
    "        type: \"bert_pooler\",\n",
    "           pretrained_model: model_name,\n",
    "           requires_grad: false,\n",
    "           dropout: 0.2,\n",
    "    },\n",
    "    initializer: {\n",
    "        regexes: [\n",
    "        [\"_text_field_embedder.*|_seq2vec_encoder.*|_classification_layer1.*|_classification_layer2.*\",\n",
    "            {\n",
    "                \"type\": \"pretrained\",\n",
    "                \"weights_file_path\": \"convbert_quarantine/fold_\" + foldnum + \"/weights.th\",\n",
    "            }\n",
    "        ],\n",
    "        ],\n",
    "    },\n",
    "  },\n",
    "  data_loader: {\n",
    "    batch_sampler: {\n",
    "      type: 'bucket',\n",
    "      batch_size: batch_size,\n",
    "    },\n",
    "  },\n",
    "  trainer: {\n",
    "    optimizer: {\n",
    "      type: \"adam\",\n",
    "      lr: lr,\n",
    "    },\n",
    "    learning_rate_scheduler: {\n",
    "      type: \"slanted_triangular\",\n",
    "      cut_frac: 0.06\n",
    "    },\n",
    "    validation_metric: '+all_mean',\n",
    "    num_serialized_models_to_keep: 1,\n",
    "    num_epochs: 20,\n",
    "    patience: 3,\n",
    "    cuda_device: 1,\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\t      metrics_epoch_4.json  out.log\n",
      "meta.json\t      metrics_epoch_5.json  predictions_test.json\n",
      "metrics_epoch_0.json  metrics_epoch_6.json  predictions_train.json\n",
      "metrics_epoch_1.json  metrics_epoch_7.json  vocabulary\n",
      "metrics_epoch_2.json  metrics.json\n",
      "metrics_epoch_3.json  model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "! ls convbert_quarantine/fold_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tune_rstbert_quarantine.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile tune_rstbert_quarantine.sh\n",
    "\n",
    "export METHOD=rstbert_quarantine\n",
    "rm -r $METHOD\n",
    "mkdir $METHOD\n",
    "export FOLD=0\n",
    "export STUDY_NAME=rstbert_test31\n",
    "\n",
    "allennlp tune configs/${METHOD}_${FOLD}.jsonnet configs/hparams.json --serialization-dir $METHOD/fold_${FOLD} \\\n",
    "    --study-name $STUDY_NAME \\\n",
    "    --skip-if-exists \\\n",
    "    --metrics best_validation_all_mean \\\n",
    "    --direction maximize\n",
    "rm rstbert_quarantine/fold_0/trial_*/*.th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_top_trials('rstbert_quarantine/fold_0/trial_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-05 12:18:54,618 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-02-05 12:18:55,039 - INFO - allennlp.common.plugins - Plugin allennlp_optuna available\n",
      "batch_size=7 dropout=0.2 lr=2.768200494663466e-05 treelstm_hidden_size=124\n"
     ]
    }
   ],
   "source": [
    "! allennlp best-params --study-name rstbert_test31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rstbert_quarantine.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile rstbert_quarantine.sh\n",
    "\n",
    "export METHOD=rstbert_quarantine\n",
    "rm -r $METHOD\n",
    "mkdir $METHOD\n",
    "export batch_size=7\n",
    "export dropout=0.2\n",
    "export lr=2e-05\n",
    "export treelstm_hidden_size=124\n",
    "\n",
    "python utils/make_k_copies.py --filename configs/${METHOD}_0.jsonnet --k 5\n",
    "\n",
    "export FOLD=0\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_quarantine_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_quarantine_rst.pkl \\\n",
    "#                  --include-package models_scripts\n",
    "\n",
    "export FOLD=1\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_quarantine_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_quarantine_rst.pkl \\\n",
    "#                  --include-package models_scripts\n",
    "\n",
    "export FOLD=2\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_quarantine_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_quarantine_rst.pkl \\\n",
    "#                  --include-package models_scripts\n",
    "\n",
    "export FOLD=3\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_quarantine_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_quarantine_rst.pkl \\\n",
    "#                  --include-package models_scripts\n",
    "\n",
    "export FOLD=4\n",
    "allennlp train -s $METHOD/fold_${FOLD} configs/${METHOD}_${FOLD}.jsonnet\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "                 --output-file $METHOD/fold_${FOLD}/predictions_test.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "                 data/fold_${FOLD}/test_quarantine_rst.pkl \\\n",
    "                 --include-package models_scripts\n",
    "                 \n",
    "# allennlp predict --use-dataset-reader --silent \\\n",
    "#                  --output-file $METHOD/fold_${FOLD}/predictions_train.json $METHOD/fold_${FOLD}/model.tar.gz \\\n",
    "#                  data/fold_${FOLD}/train_quarantine_rst.pkl \\\n",
    "#                  --include-package models_scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) A place to prep a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\n",
      "weights.th\n",
      "vocabulary/\n",
      "vocabulary/.lock\n",
      "vocabulary/labels1.txt\n",
      "vocabulary/labels2.txt\n",
      "vocabulary/non_padded_namespaces.txt\n",
      "meta.json\n"
     ]
    }
   ],
   "source": [
    "! cd rstbert_masks/fold_0/trial_19/ && tar -xzvf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('rstbert_masks/fold_0/trial_19/weights.th', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'condition_N': 5.4683037,\n",
       " 'joint_N': 5.2964687,\n",
       " 'interpretation-evaluation_S': 4.8867483,\n",
       " 'purpose_S': 4.861254,\n",
       " 'elaboration_S': 4.0842333,\n",
       " 'cause-effect_N': 3.9348679,\n",
       " 'purpose_N': 3.6049266,\n",
       " 'root': 3.126082,\n",
       " 'restatement_N': 2.8360596,\n",
       " 'evidence_N': 2.633718,\n",
       " 'evidence_S': 2.5024312,\n",
       " 'same-unit_N': 1.9227438,\n",
       " 'contrast_N': 1.642155,\n",
       " 'attribution_S': 1.4684371,\n",
       " 'sequence_N': 1.4545591,\n",
       " 'concession_S': 1.1923835,\n",
       " 'concession_N': 1.1297396,\n",
       " 'elaboration_N': 0.75989485,\n",
       " 'background_S': 0.547801,\n",
       " 'attribution_N': 0.39563867,\n",
       " 'cause-effect_S': 0.27546582,\n",
       " 'condition_S': 0.1406734,\n",
       " 'preparation_N': -0.24509633,\n",
       " 'preparation_S': -0.97542953,\n",
       " 'solutionhood_N': -1.0200452,\n",
       " 'background_N': -2.1545742,\n",
       " 'comparison_N': -2.6806216,\n",
       " 'solutionhood_S': -2.9214737,\n",
       " 'interpretation-evaluation_N': -3.2135396}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations = ['attribution_N', 'attribution_S',\n",
    "             'background_N', 'background_S',\n",
    "             'cause-effect_N', 'cause-effect_S',\n",
    "             'comparison_N',\n",
    "             'concession_N', 'concession_S',\n",
    "             'condition_N', 'condition_S',\n",
    "             'contrast_N',\n",
    "             'elaboration_N', 'elaboration_S',\n",
    "             'evidence_N', 'evidence_S',\n",
    "             'interpretation-evaluation_N', 'interpretation-evaluation_S',\n",
    "             'joint_N',\n",
    "             'preparation_S', 'preparation_N',\n",
    "             'purpose_N', 'purpose_S',\n",
    "             'restatement_N',\n",
    "             'same-unit_N',\n",
    "             'sequence_N',\n",
    "             'solutionhood_S', 'solutionhood_N',\n",
    "             'root'\n",
    "             ]\n",
    "weights = dict(zip(relations, model['_treelstm_encoder.W_iou.weight'][:,8:].sum(axis=0).detach().numpy()))\n",
    "\n",
    "{key: value for key, value in sorted(weights.items(), key=lambda x: x[1], reverse=True)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
